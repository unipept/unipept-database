#! /usr/bin/env bash

set -eo pipefail

# All references to an external script should be relative to the location of this script.
# See: http://mywiki.wooledge.org/BashFAQ/028
CURRENT_LOCATION="${BASH_SOURCE%/*}"


################################################################################
#                                    Imports                                   #
################################################################################

source "${CURRENT_LOCATION}/generate_tables_helper.sh"

################################################################################
#                            Variables and options                             #
################################################################################

# Directory used to store temporary files in
TEMP_DIR="/tmp"
# Required to reset the temporary directory after running the script
OLD_TMPDIR="$TMPDIR"

DB_TYPES="swissprot,trembl"

# Constant string used to indicate temp files generated by Unipept
UNIPEPT_TEMP_CONSTANT="unipept_temp"

# URLs that should be used to download the UniProtKB database in dat.gz format
declare -A SOURCE_URLS=(
    [swissprot]="https://ftp.expasy.org/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.dat.gz"
    [trembl]="https://ftp.expasy.org/databases/uniprot/current_release/knowledgebase/complete/uniprot_trembl.dat.gz"
)
  
TAXON_FALLBACK_URL="https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdmp.zip"
EC_CLASS_URL="https://ftp.expasy.org/databases/enzyme/enzclass.txt"
EC_NUMBER_URL="https://ftp.expasy.org/databases/enzyme/enzyme.dat"
GO_TERM_URL="http://geneontology.org/ontology/go-basic.obo"
INTERPRO_URL="http://ftp.ebi.ac.uk/pub/databases/interpro/current_release/entry.list"
REFERENCE_PROTEOME_URL="https://rest.uniprot.org/proteomes/stream?fields=upid,organism_id,protein_count&format=tsv&query=(*)+AND+(proteome_type:1)"

# Some default values for the utilities used by this script
CMD_LZ4="lz4 -c" # Which pipe compression command should I use for .lz4 files?
CMD_LZ4CAT="lz4 -dc" # Which decompression command should I use for .lz4 files?
CMD_AWK="gawk"



# Make sure that all temporary files are cleaned up if something goes wrong during execution of this script
trap terminateAndExit SIGINT
trap errorAndExit ERR
trap clean EXIT

################################################################################
#                           TABLE GENERATION FUNCTIONS                         #
#                                                                              #
# This section contains functions responsible for generating the required      #
# tables within the script. These functions handle all the necessary logic     #
# and operations to build and manage the data tables.                          #
################################################################################

extract_uniprot_version() {
  # URL of the XML file
  local xml_url="https://ftp.expasy.org/databases/uniprot/current_release/knowledgebase/complete/RELEASE.metalink"

  # Use curl to download the XML content
  local xml_content
  xml_content=$(curl -s "$xml_url")

  # Use xmllint to parse and extract the version tag value
  local version_value
  version_value=$(echo "$xml_content" | xmllint --xpath 'string(//*[local-name()="version"])' -)

  # Check if the version value is not empty
  if [[ -z "$version_value" ]]; then
    errorAndExit "No valid version tag found for UniProt."
  fi

  # Convert YYYY_MM to YYYY.MM
  local formatted_version
  formatted_version="${version_value/_/.}"

  # Write the formatted version to the .version file
  echo "$formatted_version" > "$OUTPUT_DIR/.version"
  echo "Version $formatted_version written to .version file."
}

################################################################################
# download_taxdmp                                                              #
#                                                                              #
# Downloads the taxdmp file required for generating taxon tables. This function#
# attempts to fetch the file from a self-hosted source using the GitHub API.   #
# If the self-hosted source is unavailable, a fallback URL is used.            #
#                                                                              #
# Globals:                                                                     #
#   TEMP_DIR - Directory to store temporary files                              #
#   UNIPEPT_TEMP_CONSTANT - Constant defining a sub-directory for temporary    #
#                           storage of taxdmp assets                           #
#   TAXON_FALLBACK_URL - Fallback URL to download the taxdmp file              #
#                                                                              #
# Arguments:                                                                   #
#   None                                                                       #
#                                                                              #
# Outputs:                                                                     #
#   taxdmp.zip                                                                 #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
download_taxdmp() {
  log "Starting the download of the taxdmp file."

  # Check if our self-hosted version is available or not using the GitHub API
  local latest_release_url="https://api.github.com/repos/unipept/unipept-database/releases/latest"
  local taxon_release_asset_re="unipept/unipept-database/releases/download/[^/]+/taxdmp_v2.zip"

  # Temporary disable the pipefail check (cause egrep can exit with code 1 if nothing is found).
  set +eo pipefail
  local self_hosted_url=$(curl -s "$latest_release_url" | egrep -o "$taxon_release_asset_re")
  set -eo pipefail


  if [ "$self_hosted_url" ]
  then
    log "Using self-hosted taxon dump."
    local taxon_url="https://github.com/$self_hosted_url"
  else
    log "Using fallback taxon dump."
    local taxon_url="$TAXON_FALLBACK_URL"
  fi

  curl -L --create-dirs --silent --output "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/taxdmp.zip" "$taxon_url"

  log "Finished downloading the taxdmp file."
}

################################################################################
# create_taxon_tables                                                          #
#                                                                              #
# Generates the taxon and lineage tables required for the database by          #
# downloading, parsing, processing, and filtering the data files. This function#
# downloads the latest taxon dump, processes the necessary files, filters out  #
# ranks not supported by Unipept, and generates the appropriate output files   #
# in the specified directory.                                                  #
#                                                                              #
# Globals:                                                                     #
#   TEMP_DIR          - Directory used to store temporary files                #
#   UNIPEPT_TEMP_CONSTANT - Sub-directory constant for taxon dump storage      #
#   CURRENT_LOCATION  - Current script directory                               #
#   OUTPUT_DIR        - Directory where output files are created               #
#                                                                              #
# Arguments:                                                                   #
#   None                                                                       #
#                                                                              #
# Outputs:                                                                     #
#   taxons.tsv.lz4                                                             #
#   lineages.tsv.lz4                                                           #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
create_taxon_tables() {
	log "Started creating the taxon and lineage tables."

  download_taxdmp
  unzip -qq "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/taxdmp.zip" "names.dmp" "nodes.dmp" -d "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT"
  rm "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/taxdmp.zip"

  # Replace ranks not used by Unipept by "no rank". And replace the no_rank of viruses by domain.
  sed -i'' -e 's/subcohort/no rank/' -e 's/cohort/no rank/' \
    -e 's/subsection/no rank/' -e 's/section/no rank/' \
    -e 's/series/no rank/' -e 's/biotype/no rank/' \
    -e 's/serogroup/no rank/' -e 's/morph/no rank/' \
    -e 's/genotype/no rank/' -e 's/subvariety/no rank/' \
    -e 's/pathogroup/no rank/' -e 's/forma specialis/no rank/' \
    -e 's/serotype/no rank/' -e 's/clade/no rank/' \
    -e 's/isolate/no rank/' -e 's/infraclass/no rank/' \
    -e 's/acellular root/no rank/' \
    -e 's/parvorder/no rank/' -e 's/no_rank/domain/' "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/nodes.dmp"

  log "Parsing names.dmp and nodes.dmp files"
  mkdir -p "$OUTPUT_DIR"
  "$CURRENT_LOCATION"/helper_scripts/taxons-lineages \
    --names "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/names.dmp" --nodes "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/nodes.dmp" \
    --taxons "$(lz "$OUTPUT_DIR/taxons.tsv.lz4")" \
    --lineages "$(lz "$OUTPUT_DIR/lineages.tsv.lz4")"

  rm "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/names.dmp" "$TEMP_DIR/$UNIPEPT_TEMP_CONSTANT/nodes.dmp"
  log "Finished creating the taxon and lineage tables."
}


################################################################################
# download_and_process_uniprot                                                 #
#                                                                              #
# Downloads and parses UniProtKB databases specified as a comma-separated list #
# in the first argument ($1). The function supports "swissprot" and "trembl".  #
# For each database type, it attempts to download, decompress, and convert it  #
# to a tabular format, storing the result in a compressed file in the output   #
# directory.                                                                   #
#                                                                              #
# Globals:                                                                     #
#   TEMP_DIR          - Directory to store intermediate files                  #
#   UNIPEPT_TEMP_CONSTANT - Sub-directory constant for intermediate storage    #
#   SOURCE_URLS       - Associative array mapping database types to download   #
#                       URLs                                                   #
#   CMD_LZ4           - Command or path to the lz4 binary                      #
#   CURRENT_LOCATION  - Current script directory                               #
#                                                                              #
# Arguments:                                                                   #
#   $1 - Comma-separated list of database sources to download. Supported       #
#        values are "swissprot" and "trembl".                                  #
#                                                                              #
# Outputs:                                                                     #
#   uniprot_raw.tsv.lz4 for each database type                                 #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
download_and_process_uniprot() {
  local idx=0
  
  OLDIFS="$IFS"
  IFS=","

  local db_types_array=($1)

  IFS="$OLDIFS"

  while [[ "$idx" -ne "${#db_types_array}" ]] && [[ -n $(echo "${db_types_array[$idx]}" | sed "s/\s//g") ]]
  do
    local db_type=${db_types_array[$idx]}
    local db_source=${SOURCE_URLS["$db_type"]}

    log "Started downloading and parsing UniProtKB - $db_type."

    # Where should we store the index of this converted database.
    local db_output_dir="${TEMP_DIR:?}/${UNIPEPT_TEMP_CONSTANT}/$db_type"

    # Remove previous database (if it exist) and continue building the new database.
    rm -rf "$db_output_dir"
    mkdir -p "$db_output_dir"

    # Extract the total size of the database that's being downloaded. This is required for pv to know which percentage
    # of the total download has been processed.
    local size="$(curl -I "$db_source" -s | grep -i content-length | tr -cd '[0-9]')"

    # Effectively download the database and convert to a tabular format
    curl --continue-at - --create-dirs "$db_source" --silent | pv -i 5 -n -s "$size" 2> >(reportProgress - "Downloading and parsing database for $db_type" >&2) | pigz -dc | "$CURRENT_LOCATION"/helper_scripts/dat-parser -t "$db_type" | $CMD_LZ4 > "${db_output_dir}/uniprot_raw.tsv.lz4"

    log "Finished downloading and parsing UniProtKB - $db_type."

    idx=$((idx + 1))
  done
}

################################################################################
# generate_uniprot_entries                                                     #
#                                                                              #
# Reads a raw, compressed UniProt TSV file (as generated by the                #
# download_and_process_uniprot function) provided as the first argument ($1)   #
# and produces the uniprot_entries.tsv.lz4 file as a result.                   #
#                                                                              #
# Globals:                                                                     #
#   OUTPUT_DIR         - Directory where the output files are created          #
#   CURRENT_LOCATION   - Current script directory                              #
#   PEPTIDE_MIN_LENGTH - Minimum peptide length filter                         #
#   PEPTIDE_MAX_LENGTH - Maximum peptide length filter                         #
#                                                                              #
# Arguments:                                                                   #
#   $1 - Comma-separated list of database sources to download. Supported       #
#        values are "swissprot" and "trembl".                                  #
#                                                                              #
# Outputs:                                                                     #
#   uniprot_entries.tsv.lz4 - Processed and compressed UniProt entries file    #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
generate_uniprot_entries() {
	have "$OUTPUT_DIR/taxons.tsv.lz4" || return
	log "Started generating the uniprot_entries file."

  generate_stdout() {
    # Print the header
    local idx=0

    OLDIFS="$IFS"
    IFS=","

    local db_types_array=($1)

    IFS="$OLDIFS"

    while [[ "$idx" -ne "${#db_types_array}" ]] && [[ -n $(echo "${db_types_array[$idx]}" | sed "s/\s//g") ]]
    do
      local db_file="${TEMP_DIR:?}/${UNIPEPT_TEMP_CONSTANT}/${db_types_array[$idx]}/uniprot_raw.tsv.lz4"

      $CMD_LZ4CAT $db_file

      idx=$((idx + 1))
    done
  }

	generate_stdout "$1" | "$CURRENT_LOCATION"/helper_scripts/taxons-uniprots-tables \
		--peptide-min "5" \
		--peptide-max "50" \
		--taxons "$(luz "$OUTPUT_DIR/taxons.tsv.lz4")" \
		--peptides "/dev/null" \
		--uniprot-entries "$(lz "$OUTPUT_DIR/uniprot_entries.tsv.lz4")" \
		--ec "/dev/null" \
		--go "/dev/null" \
		--interpro "/dev/null"

  log "Finished generating the uniprot_entries file."
}

################################################################################
# fetch_ec_numbers                                                             #
#                                                                              #
# Fetches EC (Enzyme Commission) numbers and descriptions, combining the EC    #
# class data and individual entries. The resulting data is saved to a          #
# compressed tab-delimited file.                                               #
#                                                                              #
# Globals:                                                                     #
#   EC_CLASS_URL - URL to fetch the EC class data                              #
#   EC_NUMBER_URL - URL to fetch the EC number data                            #
#   CMD_AWK      - Command or path to the awk binary                           #
#   CMD_LZ4      - Command or path to the lz4 binary                           #
#   OUTPUT_DIR   - Directory to save the output files                          #
#                                                                              #
# Arguments:                                                                   #
#   None                                                                       #
#                                                                              #
# Outputs:                                                                     #
#   ec_numbers.tsv.lz4 - Compressed table of EC numbers and descriptions       #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
fetch_ec_numbers() {
	log "Started creating EC numbers."
	mkdir -p "$OUTPUT_DIR"
	{
		curl -s "$EC_CLASS_URL" | grep '^[1-9]' | sed 's/\. *\([-0-9]\)/.\1/g' | sed 's/  */\t/' | sed 's/\.*$//'
		curl -s "$EC_NUMBER_URL" | grep -E '^ID|^DE' | $CMD_AWK '
			BEGIN { FS="   "
			        OFS="\t" }
			/^ID/ { if(id != "") { print id, name }
			        name = ""
			        id = $2 }
			/^DE/ { gsub(/.$/, "", $2)
			        name = name $2 }
			END   { print id, name }'
	} | cat -n | sed 's/^ *//' | $CMD_LZ4 - > "$OUTPUT_DIR/ec_numbers.tsv.lz4"
	log "Finished creating EC numbers."
}

################################################################################
# fetch_go_terms                                                               #
#                                                                              #
# Fetches Gene Ontology (GO) terms, parses their attributes, and generates a   #
# compressed tab-delimited file of GO identifiers and their related data.      #
#                                                                              #
# Globals:                                                                     #
#   GO_TERM_URL - URL to fetch the GO ontology data                            #
#   CMD_AWK     - Command or path to the awk binary                            #
#   CMD_LZ4     - Command or path to the lz4 binary                            #
#   OUTPUT_DIR  - Directory to save the output files                           #
#                                                                              #
# Arguments:                                                                   #
#   None                                                                       #
#                                                                              #
# Outputs:                                                                     #
#   go_terms.tsv.lz4 - Compressed table of GO terms and their attributes       #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
fetch_go_terms() {
	log "Started creating GO terms."
	mkdir -p "$OUTPUT_DIR"
	curl -Ls "$GO_TERM_URL" | $CMD_AWK '
		BEGIN { OFS = "	"; id = 1 }
		/^\[.*\]$/ { # start of a record
			type = $0
			alt_ctr = 0
			split("", record, ":")
			split("", ids, ":")
			next }
		/^(alt_id|id).*$/ { # a id or alt_id field in a record
			value = $0; sub("[^ ]*: ", "", value)
			record["id"][alt_ctr] = value
			alt_ctr++
			next }
		!/^$/ { # a field in a record
			key = $0;   sub(":.*", "", key)
			value = $0; sub("[^ ]*: ", "", value)
			record[key] = value }
		/^$/ { # end of a record
			if (type == "[Term]") {
				sub("_", " ", record["namespace"])
				for(i in record["id"]) {
					print id, record["id"][i], record["namespace"], record["name"]
					id++
				}
			}
			type = "" }' | $CMD_LZ4 - > "$OUTPUT_DIR/go_terms.tsv.lz4"
	log "Finished creating GO terms."
}

################################################################################
# fetch_interpro_entries                                                       #
#                                                                              #
# Fetches InterPro database entries, extracts those that start with 'IPR', and #
# saves them into a compressed tab-delimited file.                             #
#                                                                              #
# Globals:                                                                     #
#   INTERPRO_URL - URL to fetch InterPro entry data                            #
#   CMD_LZ4      - Command or path to the lz4 binary                           #
#   OUTPUT_DIR   - Directory to save the output files                          #
#                                                                              #
# Arguments:                                                                   #
#   None                                                                       #
#                                                                              #
# Outputs:                                                                     #
#   interpro_entries.tsv.lz4 - Compressed table of InterPro entries            #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
fetch_interpro_entries() {
	log "Started creating InterPro Entries."
	mkdir -p "$OUTPUT_DIR"
	curl -s "$INTERPRO_URL" | grep '^IPR' | cat -n | sed 's/^ *//' | $CMD_LZ4 - > "$OUTPUT_DIR/interpro_entries.tsv.lz4"
	log "Finished creating InterPro Entries."
}

################################################################################
# fetch_reference_proteomes                                                    #
#                                                                              #
# Fetches UniProt Reference Proteome data and generates a compressed           #
# tab-delimited file containing relevant fields.                               #
#                                                                              #
# Globals:                                                                     #
#   REFERENCE_PROTEOME_URL - URL to fetch the UniProt Reference Proteomes      #
#   CMD_LZ4                - Command or path to the lz4 binary                 #
#   OUTPUT_DIR             - Directory to save the output files                #
#                                                                              #
# Arguments:                                                                   #
#   None                                                                       #
#                                                                              #
# Outputs:                                                                     #
#   reference_proteomes.tsv.lz4 - Compressed table of UniProt Reference        #
#                                 Proteomes                                    #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
fetch_reference_proteomes() {
  log "Started creating UniProt Reference Proteomes."
  mkdir -p "$OUTPUT_DIR"
  curl -s "$REFERENCE_PROTEOME_URL" | tail -n +2 | cat -n | sed 's/^ *//' | $CMD_LZ4 - > "$OUTPUT_DIR/reference_proteomes.tsv.lz4"
  log "Finished creating UniProt Reference Proteomes."
}

################################################################################
#                                    Main                                      #
#                                                                              #
# This is the main section of the script where arguments and options are       #
# processed and the generation of output tables is initiated.                  #
################################################################################


################################################################################
# parse_arguments                                                              #
#                                                                              #
# Parses command-line arguments and validates them.                            #
#                                                                              #
# Globals:                                                                     #
#   DB_TYPES     - Comma-separated list of database sources                    #
#   OUTPUT_DIR   - Directory to save the output files                          #
#   TEMP_DIR     - Temporary directory for intermediate files                  #
#                                                                              #
# Arguments:                                                                   #
#   Command-line arguments                                                     #
#                                                                              #
# Outputs:                                                                     #
#   None                                                                       #
#                                                                              #
# Returns:                                                                     #
#   None                                                                       #
################################################################################
parse_arguments() {
  while [[ $# -gt 0 ]]; do
    case "$1" in
      --database-sources)
        DB_TYPES="$2"
        # Check if the input is a valid list of database type identifiers
        if ! [[ "$DB_TYPES" =~ ^(swissprot|trembl)(,(swissprot|trembl))*$ ]]; then
          echo "Error: --database-sources must be a comma-separated list containing only 'swissprot', 'trembl', or both."
          exit 1
        fi
        shift 2
        ;;
      --output-dir)
        OUTPUT_DIR="$2"
        shift 2
        ;;
      --temp-dir)
        TEMP_DIR="$2"
        shift 2
        ;;
      *)
        echo "Unknown argument: $1"
        exit 1
        ;;
    esac
  done

  # Check if OUTPUT_DIR is specified
  if [[ -z "$OUTPUT_DIR" ]]; then
    echo "Error: --output-dir is required"
    exit 1
  fi
}

# Now, start running the actual script and all of it's functions

# Check if all the dependencies are installed
checkdep curl
checkdep uuidgen
checkdep pv
checkdep lz4
checkdep pigz

parse_arguments "$@"
create_taxon_tables
download_and_process_uniprot "$DB_TYPES"
generate_uniprot_entries "$DB_TYPES"
fetch_ec_numbers
fetch_go_terms
fetch_interpro_entries
fetch_reference_proteomes
extract_uniprot_version
